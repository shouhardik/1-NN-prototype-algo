{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import struct\n",
    "from array import array\n",
    "from os.path  import join\n",
    "\n",
    "#\n",
    "# MNIST Data Loader Class\n",
    "#\n",
    "class MnistDataloader(object):\n",
    "    def __init__(self, training_images_filepath,training_labels_filepath,\n",
    "                 test_images_filepath, test_labels_filepath):\n",
    "        self.training_images_filepath = training_images_filepath\n",
    "        self.training_labels_filepath = training_labels_filepath\n",
    "        self.test_images_filepath = test_images_filepath\n",
    "        self.test_labels_filepath = test_labels_filepath\n",
    "    \n",
    "    def read_images_labels(self, images_filepath, labels_filepath):        \n",
    "        labels = []\n",
    "        with open(labels_filepath, 'rb') as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))\n",
    "            if magic != 2049:\n",
    "                raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "            labels = array(\"B\", file.read())        \n",
    "        \n",
    "        with open(images_filepath, 'rb') as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "            if magic != 2051:\n",
    "                raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "            image_data = array(\"B\", file.read())        \n",
    "        images = []\n",
    "        for i in range(size):\n",
    "            images.append([0] * rows * cols)\n",
    "        for i in range(size):\n",
    "            img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "            img = img.reshape(28, 28)\n",
    "            images[i][:] = img            \n",
    "        \n",
    "        return images, labels\n",
    "            \n",
    "    def load_data(self):\n",
    "        x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)\n",
    "        x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)\n",
    "        return (x_train, y_train),(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../archive/1-NN-prototype-algo/train-labels-idx1-ubyte/train-labels-idx1-ubyte'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 35\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Load MINST dataset\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     34\u001b[0m mnist_dataloader \u001b[38;5;241m=\u001b[39m MnistDataloader(training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath)\n\u001b[0;32m---> 35\u001b[0m (x_train, y_train), (x_test, y_test) \u001b[38;5;241m=\u001b[39m \u001b[43mmnist_dataloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Show some random training and test images \u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     40\u001b[0m images_2_show \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[2], line 41\u001b[0m, in \u001b[0;36mMnistDataloader.load_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 41\u001b[0m     x_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_images_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_images_filepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_labels_filepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     x_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_images_labels(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_images_filepath, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_labels_filepath)\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (x_train, y_train),(x_test, y_test)\n",
      "Cell \u001b[0;32mIn[2], line 19\u001b[0m, in \u001b[0;36mMnistDataloader.read_images_labels\u001b[0;34m(self, images_filepath, labels_filepath)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_images_labels\u001b[39m(\u001b[38;5;28mself\u001b[39m, images_filepath, labels_filepath):        \n\u001b[1;32m     18\u001b[0m     labels \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabels_filepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     20\u001b[0m         magic, size \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>II\u001b[39m\u001b[38;5;124m\"\u001b[39m, file\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m magic \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2049\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../archive/1-NN-prototype-algo/train-labels-idx1-ubyte/train-labels-idx1-ubyte'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#\n",
    "# Set file paths based on added MNIST Datasets\n",
    "#\n",
    "input_path = '../archive/1-NN-prototype-algo'\n",
    "training_images_filepath = join(input_path, 'train-images-idx3-ubyte/train-images-idx3-ubyte')\n",
    "training_labels_filepath = join(input_path, 'train-labels-idx1-ubyte/train-labels-idx1-ubyte')\n",
    "test_images_filepath = join(input_path, 't10k-images-idx3-ubyte/t10k-images-idx3-ubyte')\n",
    "test_labels_filepath = join(input_path, 't10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte')\n",
    "\n",
    "#\n",
    "# Helper function to show a list of images with their relating titles\n",
    "#\n",
    "def show_images(images, title_texts):\n",
    "    cols = 5\n",
    "    rows = int(len(images)/cols) + 1\n",
    "    plt.figure(figsize=(30,20))\n",
    "    index = 1    \n",
    "    for x in zip(images, title_texts):        \n",
    "        image = x[0]        \n",
    "        title_text = x[1]\n",
    "        plt.subplot(rows, cols, index)        \n",
    "        plt.imshow(image, cmap=plt.cm.gray)\n",
    "        if (title_text != ''):\n",
    "            plt.title(title_text, fontsize = 15);        \n",
    "        index += 1\n",
    "\n",
    "#\n",
    "# Load MINST dataset\n",
    "#\n",
    "mnist_dataloader = MnistDataloader(training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath)\n",
    "(x_train, y_train), (x_test, y_test) = mnist_dataloader.load_data()\n",
    "\n",
    "#\n",
    "# Show some random training and test images \n",
    "#\n",
    "images_2_show = []\n",
    "titles_2_show = []\n",
    "for i in range(0, 10):\n",
    "    r = random.randint(1, 60000)\n",
    "    images_2_show.append(x_train[r])\n",
    "    titles_2_show.append('training image [' + str(r) + '] = ' + str(y_train[r]))    \n",
    "\n",
    "for i in range(0, 5):\n",
    "    r = random.randint(1, 10000)\n",
    "    images_2_show.append(x_test[r])        \n",
    "    titles_2_show.append('test image [' + str(r) + '] = ' + str(y_test[r]))    \n",
    "\n",
    "show_images(images_2_show, titles_2_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def select_prototypes_kmeans(x_train, y_train, num_prototypes):\n",
    "    \"\"\"\n",
    "    Enhanced prototype selection with debugging information.\n",
    "    \"\"\"\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    # Flatten images\n",
    "    x_flat = np.array([img.flatten() for img in x_train])\n",
    "    \n",
    "    print(f\"Training data shape: {x_train.shape}\")\n",
    "    print(f\"Flattened data shape: {x_flat.shape}\")\n",
    "    print(f\"Number of prototypes requested: {num_prototypes}\")\n",
    "    \n",
    "    # Perform K-means clustering\n",
    "    kmeans = KMeans(n_clusters=min(num_prototypes, len(x_train)), random_state=42)\n",
    "    kmeans.fit(x_flat)\n",
    "    \n",
    "    # Find closest points to cluster centers (prototypes)\n",
    "    prototype_indices = []\n",
    "    for center in kmeans.cluster_centers_:\n",
    "        # Find the training point closest to each cluster center\n",
    "        distances = np.linalg.norm(x_flat - center, axis=1)\n",
    "        closest_idx = np.argmin(distances)\n",
    "        prototype_indices.append(closest_idx)\n",
    "    \n",
    "    # Select prototype images and labels\n",
    "    prototype_images = x_train[prototype_indices]\n",
    "    prototype_labels = y_train[prototype_indices]\n",
    "    \n",
    "    print(f\"Prototype images shape: {prototype_images.shape}\")\n",
    "    print(f\"Prototype labels shape: {prototype_labels.shape}\")\n",
    "    \n",
    "    return prototype_images, prototype_labels\n",
    "\n",
    "def custom_1nn_classifier(test_image, prototypes, prototype_labels):\n",
    "    \"\"\"Custom 1-NN classifier with float64 conversion.\"\"\"\n",
    "    # Ensure float64 conversion\n",
    "    test_image_flat = test_image.flatten().astype(np.float64)\n",
    "    prototype_flat = np.array([img.flatten().astype(np.float64) for img in prototypes])\n",
    "    \n",
    "    # Calculate distances\n",
    "    distances = np.linalg.norm(prototype_flat - test_image_flat, axis=1)\n",
    "    \n",
    "    # Find nearest prototype\n",
    "    nearest_idx = np.argmin(distances)\n",
    "    \n",
    "    return prototype_labels[nearest_idx]\n",
    "\n",
    "def evaluate_prototype_selection(x_train, y_train, x_test, y_test, num_prototypes):\n",
    "    \"\"\"\n",
    "    Evaluate prototype selection with more detailed logging.\n",
    "    \"\"\"\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    x_test = np.array(x_test)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    # Select prototypes using K-means\n",
    "    prototypes, prototype_labels = select_prototypes_kmeans(\n",
    "        x_train, y_train, num_prototypes\n",
    "    )\n",
    "    \n",
    "    # Predict labels for test set\n",
    "    predictions = []\n",
    "    for test_image in x_test:\n",
    "        pred = custom_1nn_classifier(test_image, prototypes, prototype_labels)\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(np.array(predictions) == y_test)\n",
    "    \n",
    "    print(f\"Unique training labels: {np.unique(y_train)}\")\n",
    "    print(f\"Unique prototype labels: {np.unique(prototype_labels)}\")\n",
    "    print(f\"Unique prediction labels: {np.unique(predictions)}\")\n",
    "    \n",
    "    return accuracy, prototypes, prototype_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (60000, 28, 28)\n",
      "Flattened data shape: (60000, 784)\n",
      "Number of prototypes requested: 1000\n",
      "Prototype images shape: (1000, 28, 28)\n",
      "Prototype labels shape: (1000,)\n",
      "Unique training labels: [0 1 2 3 4 5 6 7 8 9]\n",
      "Unique prototype labels: [0 1 2 3 4 5 6 7 8 9]\n",
      "Unique prediction labels: [0 1 2 3 4 5 6 7 8 9]\n",
      "Accuracy on test data: 92.31%\n"
     ]
    }
   ],
   "source": [
    "# Call the function and print accuracy percentage\n",
    "accuracy, prototypes, prototype_labels = evaluate_prototype_selection(x_train, y_train, x_test, y_test, 1000)\n",
    "print(f\"Accuracy on test data: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def random_prototype_selection(x_train, y_train, num_prototypes, random_state=42):\n",
    "    \"\"\"\n",
    "    Randomly select prototypes while maintaining label distribution.\n",
    "    \n",
    "    Args:\n",
    "        x_train (numpy.ndarray): Training images\n",
    "        y_train (numpy.ndarray): Training labels\n",
    "        num_prototypes (int): Number of prototypes to select\n",
    "        random_state (int): Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Selected prototype images and their corresponding labels\n",
    "    \"\"\"\n",
    "    # Ensure numpy arrays and float64\n",
    "    x_train = np.array(x_train, dtype=np.float64)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    # Get unique labels\n",
    "    unique_labels = np.unique(y_train)\n",
    "    \n",
    "    # Calculate prototypes per label (proportional to original distribution)\n",
    "    prototypes_per_label = np.round(\n",
    "        num_prototypes * np.bincount(y_train) / len(y_train)\n",
    "    ).astype(int)\n",
    "    \n",
    "    # Adjust to ensure total matches num_prototypes\n",
    "    while np.sum(prototypes_per_label) != num_prototypes:\n",
    "        if np.sum(prototypes_per_label) < num_prototypes:\n",
    "            prototypes_per_label[np.argmin(prototypes_per_label)] += 1\n",
    "        else:\n",
    "            prototypes_per_label[np.argmax(prototypes_per_label)] -= 1\n",
    "    \n",
    "    # Set random seed\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Select prototypes\n",
    "    prototype_images = []\n",
    "    prototype_labels = []\n",
    "    \n",
    "    for label, num_proto in zip(unique_labels, prototypes_per_label):\n",
    "        # Find indices of images with this label\n",
    "        label_indices = np.where(y_train == label)[0]\n",
    "        \n",
    "        # Randomly select prototypes for this label\n",
    "        selected_indices = np.random.choice(\n",
    "            label_indices, \n",
    "            size=num_proto, \n",
    "            replace=False\n",
    "        )\n",
    "        \n",
    "        prototype_images.append(x_train[selected_indices])\n",
    "        prototype_labels.append(y_train[selected_indices])\n",
    "    \n",
    "    # Concatenate results\n",
    "    prototype_images = np.concatenate(prototype_images)\n",
    "    prototype_labels = np.concatenate(prototype_labels)\n",
    "    \n",
    "    return prototype_images, prototype_labels\n",
    "\n",
    "def custom_1nn_classifier(test_image, prototypes, prototype_labels):\n",
    "    \"\"\"Custom 1-NN classifier with float64 conversion\"\"\"\n",
    "    test_image_flat = test_image.flatten().astype(np.float64)\n",
    "    prototype_flat = np.array([img.flatten().astype(np.float64) for img in prototypes])\n",
    "    \n",
    "    # Calculate distances\n",
    "    distances = np.linalg.norm(prototype_flat - test_image_flat, axis=1)\n",
    "    \n",
    "    # Find nearest prototype\n",
    "    nearest_idx = np.argmin(distances)\n",
    "    \n",
    "    return prototype_labels[nearest_idx]\n",
    "\n",
    "def evaluate_prototype_selection(x_train, y_train, x_test, y_test, num_prototypes):\n",
    "    \"\"\"Evaluate random prototype selection\"\"\"\n",
    "    # Convert to float64\n",
    "    x_train = np.array(x_train, dtype=np.float64)\n",
    "    y_train = np.array(y_train)\n",
    "    x_test = np.array(x_test, dtype=np.float64)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    # Select prototypes randomly\n",
    "    prototypes, prototype_labels = random_prototype_selection(\n",
    "        x_train, y_train, num_prototypes\n",
    "    )\n",
    "    \n",
    "    # Predict labels for test set\n",
    "    predictions = []\n",
    "    for test_image in x_test:\n",
    "        pred = custom_1nn_classifier(test_image, prototypes, prototype_labels)\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(np.array(predictions) == y_test)\n",
    "    \n",
    "    return accuracy, prototypes, prototype_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 70.96%\n"
     ]
    }
   ],
   "source": [
    "# Call the function and print accuracy percentage\n",
    "accuracy, prototypes, prototype_labels = evaluate_prototype_selection(x_train, y_train, x_test, y_test, 100)\n",
    "print(f\"Accuracy on test data: {accuracy * 100:.2f}%\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
